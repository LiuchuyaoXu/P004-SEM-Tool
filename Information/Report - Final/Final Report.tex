\newcommand{\CLASSINPUTbaselinestretch}{1.5}
\newcommand{\CLASSINPUTinnersidemargin}{25mm}
\documentclass[12pt, conference]{IEEEtran}
\usepackage{algorithmic}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{caption,subcaption}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{textcomp}
\usepackage{xcolor}

\def\BibTeX{
    {\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}
}

\begin{document}
\title{Real-time Diagnostic Tools for the Scanning Electron Microscope}
\author{
    \IEEEauthorblockN{Liuchuyao Xu}
    \IEEEauthorblockA{\textit{Robinson College}}
}
\maketitle

\begin{abstract}
\end{abstract}

\section{Introduction}
The scanning electron microscope (SEM) is a type of microscope that produces images using signals generated from the interaction between electrons and the surface under observation. Higher resolution can be achieved compared to the traditional optical microscope, since electrons have much lower wavelength than light. An SEM can have resolution lower than one nanometre, whereas that of an optical microscope is often limited to a few hundred nanometres \cite{SEM wiki}. This has benefited a variety of fields. For example, scientists have been using the SEM to analyse the doping density in semiconductors \cite{SEM for semiconductor} and to view changes in bacterial cells \cite{SEM for bacterial cells}.

Fig. \ref{SEM basic construction} shows the basic construction of an SEM. The electron gun generates an electron beam, which is transformed into an electron probe after passing through the condenser lens and objective lens. It is scanned across the specimen under the effect of the scanning coil. As a result of the interaction between the incident electrons and the specimen, some electrons are emitted from the specimen. These are called secondary electrons and are collected by the detector, which generates signals whose magnitude depend on the strength of the secondary electrons. The display unit produces one frame after each complete scan of the specimen.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.4\textwidth]{Images/SEM basic construction.jpg}
    \caption{Basic construction of an SEM \cite{SEM A to Z}.}
    \label{SEM basic construction}
\end{figure}

The quality of an SEM image is affected by aberrations. While some exist because of the fundamental properties of the microscope and are difficult to get rid of, some can be completely eliminated by adjusting relevant settings. Two important ones are focus and stigmation, which directly affect the resolution and astigmatism of the image, respectively. Fig. \ref{Sample SEM images} illustrates the effect of wrong focus and stigmation settings.

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.4\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{Images/A in focus.jpg}
        \caption{In focus.}
        \label{A in focus}
    \end{subfigure}
    \begin{subfigure}{0.4\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{Images/A out of focus.jpg}
        \caption{Out of focus.}
        \label{A out of focus}
    \end{subfigure}
    \begin{subfigure}{0.4\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{Images/A astigmatism.jpg}
        \caption{In focus with astigmatism.}
        \label{A astigmatism}
    \end{subfigure}
    \caption{Sample SEM images.}
    \label{Sample SEM images}
\end{figure}

Focus determines the focal point of the electron probe. When the focal point is far from the surface of the specimen, the incident electrons interact with the specimen in a larger area. As a result, spots near each other produce signals of closer magnitude. This makes the image appear blurry, as shown in Fig. \ref{A out of focus}.

Stigmation controls stigmators in the SEM, which are used to compensate for astigmatism. Astigmatism arises due to imperfections in components of the SEM, and describes uneven focus in the electron probe, as shown in Fig. \ref{SEM uneven focus}. When the electron probe is out of focus, astigmatism makes the incident electrons interact with the specimen in an elliptical area, and thus makes the image appear stretched. When the electron probe is in focus, astigmatism makes the image appear blurry. Fig. \ref{Sample astigmatic SEM images} gives some examples of distorted images.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.4\textwidth]{Images/SEM uneven focus.jpg}
    \caption{Uneven focus of the SEM.}
    \label{SEM uneven focus}
\end{figure}

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.4\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{Images/B astigmatic a.jpeg}
        \caption{Astigmatic images}
        \label{B astigmatic a}
    \end{subfigure}
    \begin{subfigure}{0.4\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{Images/B astigmatic b.jpeg}
        \caption{Astigmatic and non-astigmatic image}
        \label{B astigmatic b}
    \end{subfigure}
    \caption{Sample astigmatic SEM images \cite{SEM astigmatism correction}.}
    \label{Sample astigmatic SEM images}
\end{figure}

Although experienced SEM operators can often find the right settings for focus and stigmation in a short time, it may not be as straightforward for new users. Sometimes, the surface being observed may have a complex structure and makes adjusting even harder. The complexity arises because any judgement of an image is based on what the operators see through their eyes, which is rather subjective. Intensive training and practical experience are often required for an operator to become efficient in using the SEM.

Fast computing can aid the operators in a few ways. Firstly, a numerical evaluation of the quality of the image may be provided, which eliminates the subjectivity in using human eyes. Numbers are also easier to note down if any record is required. Two operators may have different views on the same image, but the numbers will not be different. Therefore, cooperation and communication between operators can be enhanced. The use of numbers also enable automatic procedures for adjusting settings of the SEM, which save time and may produce better results than doing it manually.

\section{GPU, fast computing and the project}
The graphics processing unit (GPU) was originally designed to efficiently manipulate data in order to accelerate the rendering of 3D images on displays. Depending on the position, pixels in a 3D image may require different processing to achieve effects such as lighting, blurring and fogging. This is achieved by breaking down the image into a massive number of fragments and processing each fragment individually. The processes happen independently but may share the same logical sequence of control, and this pattern is named single instruction multiple data (SIMD). A GPU consists of a large array of processing cores, with each of them using SIMD to process a block of fragments.

The characteristic of the GPU allows it to outperform central processing units (CPUs) when performing algorithms that manipulate data in parallel. Take the dot product between two vectors of size 1000 as an example, the processing cores on the GPU may be 100 times slower than the CPU, but if 1000 of them work in parallel and each computes the multiplication of one element from each vector, the overall speed will be 10 times faster. This has allowed computer vision programs that were previously impossible or computationally too expensive to build. For example, a wearable mediated reality device that make computer-generated information appear to the user as though it was anchored in the real world \cite{Mediated reality using GPU}.

The goal of the project is to develop software tools based on fast computation provided by the GPU, to support interactive real-time diagnosis of SEM images for the purpose of assisting the operator or automating procedures, which has only been practicable off-line.

\section{Algorithms}
\subsection{Histogram Equalisation} \label{Histogram Equalisation}
There are many types of histograms in image processing. The grey level (brightness level) pixel intensity histogram, which plots the number of pixels of each grey value in the image, is the most relevant one for SEM images. This is because an SEM translates the energy of the secondary electrons directly into a grey level, colours do not exist in SEM images.

The algorithm for obtaining the histogram of an SEM image is given by
\begin{equation}
    n_l = \frac{1}{P} \sum_{p} I(l_p=l),
\end{equation}
where $n_l$ is the normalised number of pixels of grey level $l$, $P$ is the total number of pixels in the image and $l_p$ is the grey level of the $p_{th}$ pixel. 

Fig. \ref{C original} shows an 8-bit grey-scale image, i.e. its depth of digitisation is 8-bit and it has 256 grey levels. Fig. \ref{C original histogram} shows the histogram of the image and its integral. As can be seen in the histogram, most pixels are concentrated in the middle of the grey scale. This is reflected by the fact that the image is missing its highlights and shadows.

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.4\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{Images/C original.jpg}
        \caption{Original image.}
        \label{C original}
    \end{subfigure}
    \begin{subfigure}{0.4\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{Images/C original histogram.png}
        \caption{Histogram of the original image.}
        \label{C original histogram}
    \end{subfigure}
    \begin{subfigure}{0.4\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{Images/C equalised.jpg}
        \caption{Histogram-equalised image.}
        \label{C equalised}
    \end{subfigure}
    \begin{subfigure}{0.4\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{Images/C equalised histogram.png}
        \caption{Histogram of the histogram-equalised image.}
        \label{C equalised histogram}
    \end{subfigure}
    \caption{Histogram and histogram equalisation \cite{Histogram equalisation wiki}.}
    \label{Histogram and histogram equalisation}
\end{figure}

Histogram equalisation is a method for adjusting the distribution of pixel intensities of an image, in order to improve its overall contrast. Effectively, it is achieved by spreading out the more frequent intensity values. To perform histogram equalisation, first obtain the integral of the histogram using
\[s_l = \sum_{i=1}^{l} n_i,\]
where $s_l$ is the value of the integral at grey level $l$. The integral spans from 0 to 1 as the histogram is normalised. Scale the integral by the maximum grey level and preform rounding to create the transform function
\begin{equation}
    f_l = \lfloor s_lL \rfloor,
    \label{Histogram equalisation transform function}
\end{equation}
If a pixel in the original image has grey level $l$, it will have grey level $f_l$ in the transformed image. For example, if all pixels in the original image are concentrated between grey level 100 to 200, the pixels of level 100 will become 0 in the new image while the pixels of level 200 will become 255 (assuming 8-bit image).

The result is more noticeable when the image has a low contrast, such as the one shown in Fig. \ref{C original}. The histogram-equalised version of it is given in Figure \ref{C equalised} and the new histogram in Fig. \ref{C equalised histogram}. More details are now visible as the contrast has been enhanced.

\subsection{Fast Fourier Transform}
The Fourier transform (FT) decomposes a function into its constituent frequencies, as illustrated in Fig. \ref{FT}. The function in red is can be represented by a superposition of all the sinusoidal functions shown, each having a unique frequency and with magnitudes as indicated on the right panel. A function that changes more abruptly will have stronger high-frequency components than a smoother one. 

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.4\textwidth]{Images/FT.jpg}
    \caption{Fourier transform \cite{Fourier transform wiki}.}
    \label{FT}
\end{figure}

In image processing, the discrete Fourier transform (DFT) is often preferred, which takes a finite sequence of equally-spaced values as input and is thus better suited than the FT. It is defined by
\begin{equation}
    X_k = \sum_{n=0}^{N-1} x_n \cdot e^{-i2\pi kn/N}, \quad 0 \leq k \leq N-1,
    \label{DFT}
\end{equation}
where $x_0,x_1,...,x_{N-1}$ is the input sequence and $X_0,X_1,...,X_{N-1}$ is the output sequence. $X_k$ is effectively the result of the dot product between the vector $[x_0,x_1,...,x_{N-1}]$ and $[e^0,e^{-i2\pi k/N},...,,e^{-i2\pi k(N-1)/N}]$, and the latter is a finite sequence of frequency $2\pi k$. Therefore, the DFT computes the magnitude of the component of the input sequence with frequency $2\pi k$, for $0 \leq k \leq N-1$.

Fig. \ref{FFT on images} gives an example of FFT applied on a real image. The top row shows a set of images and the bottom row shows the corresponding transforms (amplitudes only). Points near the origin represent lower-frequency components and are cut off when a high-pass filter is applied to the image.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.4\textwidth]{Images/FFT on images.jpg}
    \caption{FFT and filtering on images \cite{Fourier transform lecture}.}
    \label{FFT on images}
\end{figure}

A drawback of using \eqref{DFT} is that it has a time complexity of $O(N^2)$. In image processing, where the inputs are 2D sequences, the time complexity quickly explodes and makes the equation practically impossible to use. A fast Fourier transform (FFT) is an algorithm that computes the DFT with smaller timer complexity. There are many feasible algorithms and all known ones have complexity $O(N\log N)$ \cite{Fast Fourier transform wiki}. Detailed discussion on FFT algorithms is beyond the scope of this report.

\subsection{Focusing and Astigmatism Correction}
The focusing and astigmatism of an SEM image can be evaluated using its FFT. Fig. \ref{SEM astigmatism} provides a set of sample images that illustrate how different degrees of defocus and astigmatism affect the image and its FFT. An in-focus image contains more details, and its FFT will thus have stronger high-frequency components. As an astigmatic image goes from under-focus from over-focus, the elliptical incidence area of the electron probe rotates by 90 degrees and makes the image appear stretched in the new direction. As a result, its FFT also rotates by 90 degrees. K.H. Ong, J.C.H. Phang and J.T.L. Thong proposed an algorithm for automatic focusing and astigmatism correction \cite{SEM astigmatation correction algorithm} using these properties.

\begin{figure*}[htbp]
    \centering
    \includegraphics[width=1\textwidth]{Images/SEM astigmatism.jpg}
    \caption{Images of gold-on-carbon sample and their fast Fourier transforms (FFTs) for different degrees of defocus and astigmatism \cite{SEM astigmatation correction algorithm}.}
    \label{SEM astigmatism}
\end{figure*}

The FFT of an image can be converted into a binary image by applying a threshold to the magnitudes, and segmented into 8 regions as shown in Fig. \ref{FFT regions}. A pixel has value 1 if the magnitude is above the threshold and 0 otherwise. Let $I$ be a matrix representing the current image with focal length set to $F$, obtain an under-focused image $I_{uf}$ and over-focused image $I_{of}$ by setting the focal length to $F-\Delta F=F_{uf}$ and $F+\Delta F=F_{of}$, respectively. Let $FI$, $FI_{uf}$ and $FI_{of}$ be matrices representing the binary FFT of $I$, $I_{uf}$ and $I_{of}$, respectively.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.4\textwidth]{Images/FFT regions.jpg}
    \caption{Segmented fast Fourier transform \cite{SEM astigmatation correction algorithm}.}
    \label{FFT regions}
\end{figure}

The focal length can be adjusted by comparing the sum of pixel values in $FI$, $FI_{uf}$ and $FI_{of}$. Let the perfect focal length for the image be $\hat{F}$, then
\begin{align*}
\begin{cases}
    \text{sum}(FI_{of}) < \text{sum}(FI) < \text{sum}(FI_{uf}), \quad & \hat{F} < F_{uf} \\
    \text{sum}(FI_{of}) < \text{sum}(FI_{uf}), \quad & F_{uf} < \hat{F} < F \\
    \text{sum}(FI_{of}) = \text{sum}(FI_{uf}) < \text{sum}(FI), \quad & F=\hat{F} \\
    \text{sum}(FI_{uf}) < \text{sum}(FI_{of}), \quad & F_{of} > \hat{F} > F \\
    \text{sum}(FI_{uf}) < \text{sum}(FI) < \text{sum}(FI_{of}), \quad & \hat{F} > F_{of}
\end{cases}.
\end{align*}
Let
\begin{equation}
    P = \text{sum}(FI_{of}) - \text{sum}(FI_{uf}).
\end{equation}
Then, the rules for adjusting focal length are
\begin{itemize}
    \item when $P>0$, the focal length should be decreased.
    \item when $P<0$, the focal length should be increased.
\end{itemize}

After the focal length has been set to the perfect value, i.e. when $F=\hat{F}$, the stigmator settings can be determined by comparing the sum of pixel values in different regions of $FI$, $FI_{uf}$ and $FI_{of}$. The rules for adjustment can be determined using Fig. \ref{SEM astigmatism}. Let
\begin{align}
    P_{R12} & = \text{sum}(FI_{of,R12}) - \text{sum}(FI_{uf,R12}), \\
    P_{R34} & = \text{sum}(FI_{of,R34}) - \text{sum}(FI_{uf,R34}), \\
    P_{S12} & = \text{sum}(FI_{of,S12}) - \text{sum}(FI_{uf,S12}), \\
    P_{S34} & = \text{sum}(FI_{of,S34}) - \text{sum}(FI_{uf,S34}).
\end{align}
Then the rules for adjusting stigmator settings are
\begin{itemize}
    \item when $P_{R12}>0$ and $P_{R34}<0$, stigma x should be decreased.
    \item when $P_{R12}<0$ and $P_{R34}>0$, stigma x should be increased.
    \item when $P_{S12}>0$ and $P_{S34}<0$, stigma y should be increased.
    \item when $P_{S12}<0$ and $P_{S34}>0$, stigma y should be decreased.
\end{itemize}

Fig. \ref{Correction algorithm flowchart} shows the general flow chart of the algorithm.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.45\textwidth]{Images/Correction algorithm flowchart.jpg}
    \caption{General flow chart of the correction algorithm \cite{SEM astigmatation correction algorithm}.}
    \label{Correction algorithm flowchart}
\end{figure}

\section{The Software}
\subsection{Overview}
The software controls the SEM and takes images from it using its application programming interface (API). The API provided by the manufacturer supports only C++. To make development easier, a Python wrapper (SEM\_API.py) for the native API has been written by Luyang Han and is used by the software.

The architecture of the software is designed with a priority on maintainability. There are four modules in the software --- \textit{SemTool}, \textit{SemImage}, \textit{SemCorrector} and \textit{Masker}. \textit{SemTool} handles the graphical user interface (GUI), \textit{SemImage} provides a class for containing an SEM image, \textit{SemCorrector} provides the automatic focusing and astigmatism correction algorithm and uses \textit{Masker} to efficiently segment the FFTs of images. The class diagram of the software is given in Fig. \ref{Software classes}, showing only the major classes. The modularity improves the readability of the code and makes it easier to maintain and develop.

The Python \textit{numpy} and \textit{cupy} library are the main packages used for performing mathematical operations. \textit{Numpy} provides an interface to be used in Python, but implements the functions using C code at the bottom level, which run on the CPU directly and improve performance. \textit{Cupy} provides a similar interface as \textit{numpy}, but runs the code on the GPU. The parallel processing power of the GPU can make \textit{cupy} way faster than \textit{numpy} for calculations involving matrices, such as calculating the FFT of an image. To ensure good performance, algorithms written in pure Python are avoided wherever possible.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.45\textwidth]{Images/Software classes.png}
    \caption{Class diagram of the software in unified modelling language (UML)}
    \label{Software classes}
\end{figure}

Fig. \ref{Software screenshot} shows a screenshot of the GUI. The push buttons open a window for the corresponding plot and the radio buttons select algorithms to be performed on the image. The plots are shown on different windows, and can be opened and closed individually. This improves frame rate by allowing the user to close unneeded windows, and also makes it easier to add other plots later. Table \ref{Software framerates} shows that the improvement is rather significant, as rendering windows is the most time-consuming process in the software. Most of the time, the only window needed is the FFT plot, which means a framerate of about 16 is possible. The automatic focusing and astigmatism correction algorithm has not been fully tested due to the impact of the COVID-19 pandemic, and is therefore not yet integrated to the GUI.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.4\textwidth]{Images/Software screenshot.jpg}
    \caption{Screenshot of the Software.}
    \label{Software screenshot}
\end{figure}

\begin{table}[htbp]
    \caption{Results of software framerate test}
    \begin{center}
    \begin{tabular}{|c|c|}
    \hline
     & \textbf{Framerate} \\
    \hline
    no windows, no algorithms & 10 ms \\
    \hline
    one window, no algorithms & 60 ms \\
    \hline
    three windows, no algorithms & 180 ms \\
    \hline
    three windows, two algorithms & 200 ms \\
    \hline
    \multicolumn{2}{l}{$^{\mathrm{a}}$The numbers are approximate.} \\
    \multicolumn{2}{l}{$^{\mathrm{b}}$With Intel Core i7 and NVIDIA GeForce GTX 1060.}
    \end{tabular}
    \label{Software framerates}
    \end{center}
\end{table}

\subsection{SemImage}
Fig. \ref{Software SemImage} shows the \textit{SemImage} class. It encapsulates all variables and methods that are directly relevant to an image taken by the SEM. Each \textit{SemImage} contains three \textit{numpy.ndarray} instances --- \textit{array}, \textit{fft} and \textit{histogram}, which store data of the image, its FFT and histogram, respectively.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.4\textwidth]{Images/Software SemImage.png}
    \caption{\textit{SemImage} class.}
    \label{Software SemImage}
\end{figure}

An image is effectively a finite sequence of data, and this can cause boundary effect when its FFT is calculated. The abrupt discontinuity at the edges gives the FFT some strong high-frequency components. To circumvent this, the \textit{SemImage} class provides two methods --- \textit{applyHamming()} and \textit{applyHanning()}, which apply a Hamming and Hanning window function to the image data, respectively. The window functions taper the edges off towards zero, and thus reduce the boundary effect. Fig. \ref{Window functions} illustrates how they look like, and they can be obtained by setting $a_0$ to $0.5$ and $25/46$, respectively, in the function
\begin{equation}
    w[n] = a_0 - (1-a_0)\cdot \cos{\frac{2\pi n}{N}}, \quad 0\leq n \leq N.
\end{equation}

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{Images/Window Hamming.png}
        \caption{Hamming window.}
        \label{Window Hamming}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{Images/Window Hanning.png}
        \caption{Hanning window.}
        \label{Window Hanning}
    \end{subfigure}
    \caption{Window functions \cite{Window function wiki}.}
    \label{Window functions}
\end{figure}

The \textit{applyHistogramEqualisation()} method implements the algorithm as described in \ref{Histogram Equalisation}. The most time-consuming part of the algorithm is to map all pixels in the original image to their new values using the transform function \eqref{Histogram equalisation transform function}. To achieve good performance, the software uses the Python \textit{map()} function together with the \textit{lambda} operator, which iterates through all pixels in the image and thus has time complexity of $O(N^2)$. This is not optimal and better complexity may be achieved by utilising the GPU. However, that would make the code more complex and harder to read, since the \textit{cupy} package does not provide a straightforward solution to it. With \textit{map()} and \textit{lambda}, the transformation can be implemented in one line:
\begin{lstlisting}[language=Python]
    map(lambda x: trans[x], image)
\end{lstlisting}
\textit{trans} is an array that serves as the transformation function, if the original pixel value is \textit{x}, the new value should be \textit{trans[x]}. The \textit{lambda} operator is a way to create small anonymous functions, which are throw-away functions and are only needed where they are created. \textit{lambda x: trans[x]} creates an anonymous function which returns \textit{trans[x]} when given \textit{x}, and \textit{map()} uses this function to transform all pixels in \textit{image}.

Both \textit{updateFft()} and \textit{updateHistogram()} use functions in \textit{cupy} to perform the calculations. Since \textit{cupy} may not always be available due do the hardware environment, the software automatically switches to \textit{numpy} when \textit{cupy} cannot be used.

The following code demonstrate how to initialise an \textit{SemImage} instance, apply Hamming window to the image, copy its FFT to the variable \textit{fft} and apply histogram equalisation to it.
\begin{lstlisting}[language=Python]
    image = SemImage(data)
    image.applyHamming()
    fft = image.fft
    image.applyHistogramEqualisation()
\end{lstlisting}

\subsection{Masker}
A key factor that affects the performance of the automatic focusing and astigmatism correction algorithm is the speed of performing segmentation on the FFTs. The most straightforward way of doing it is to iterate through the whole matrix while calculating the sums in pure Python, for every FFT. This has a time complexity of $O(N^2)$. The \textit{Masker} module provides a faster solution.

A \textit{Masker} can be initialised with a 2D shape, and it will create eight matrices, each representing a region as shown in Fig. \ref{FFT regions}. For example, if the input is $[5, 7]$, the matrix created for region R1 will be
\begin{align*}
\begin{bmatrix}
1 & 1 & 1 & 1 & 1 & 1 & 1\\
1 & 1 & 1 & 1 & 1 & 1 & 0\\
1 & 1 & 1 & 0 & 0 & 0 & 0\\
1 & 1 & 1 & 1 & 1 & 1 & 0\\
1 & 1 & 1 & 1 & 1 & 1 & 1
\end{bmatrix}.
\end{align*}
The algorithm ensures that there is no overlapping between matrices apart from at the center. After obtaining the matrix for region R1, the sum of of values in an FFT in R1 can be calculated using the \textit{numpy.ma} module:
\begin{lstlisting}[language=Python]
    ma.array(fft, mask=masker.r1).sum()
\end{lstlisting}

\begin{thebibliography}{00}
    \bibitem{SEM wiki}
    "Scanning electron microscope." en.wikipedia.org. \url{https://en.wikipedia.org/wiki/Scanning_electron_microscope} (accessed May 9, 2020).

    \bibitem{SEM for semiconductor}
    T. Agemura and T. Sekiguchi, "Secondary electron spectroscopy for imaging semiconductor materials," 2018 International Symposium on Semiconductor Manufacturing (ISSM), Tokyo, Japan, 2018, pp. 1-3, doi: 10.1109/ISSM.2018.8651171.

    \bibitem{SEM for bacterial cells}
    T. Cushnie, N. O’Driscoll and A. Lamb, "Morphological and ultrastructural changes in bacterial cells as an indicator of antibacterial mechanism of action", Cellular and Molecular Life Sciences, vol. 73, no. 23, pp. 4471-4492, 2016. Available: 10.1007/s00018-016-2302-2 [Accessed 17 May 2020].

    \bibitem{SEM A to Z}
    \textit{Scanning Electron Microscope A to Z}. JEOL Ltd. [Online]. Available: \url{https://www.jeol.co.jp/en/applications/pdf/sm/sem_atoz_all.pdf}. Accessed: May 9, 2020.

    \bibitem{SEM astigmatism correction}
    "Correcting Astigmatism in SEM Images." cambridge.org. \url{https://www.cambridge.org/core/journals/microscopy-today/article/correcting-astigmatism-in-sem-images/7ED43987C7916AAFBE1869522546AC84/core-reader} (accessed May 10, 2020).

    \bibitem{Mediated reality using GPU}
    Fung, et al., "Mediated Reality Using Computer Graphics Hardware for Computer Vision" Archived 2 April 2012 at the Wayback Machine, Proceedings of the International Symposium on Wearable Computing 2002 (ISWC2002), Seattle, Washington, USA, 7–10 October 2002, pp. 83–89.

    \bibitem{Histogram equalisation wiki}
    "Histogram equalization." en.wikipedia.org. \url{https://en.wikipedia.org/wiki/Histogram_equalization} (accessed May 11, 2020).

    \bibitem{Fourier transform wiki}
    "Fourier transform." en.wikipedia.org. \url{https://en.wikipedia.org/wiki/Fourier_transform} (accessed May 12, 2020).

    \bibitem{Fourier transform lecture}
    University of Oxford. (2014). 2D Fourier transforms and applications. [Online]. Available: \url{http://www.robots.ox.ac.uk/}

    \bibitem{Fast Fourier transform wiki}
    "Fast Fourier transform." en.wikipedia.org. \url{https://en.wikipedia.org/wiki/Fast_Fourier_transform} (accessed May 12, 2020).
    
    \bibitem{SEM astigmatation correction algorithm}
    K.H. Ong, J.C.H. Phang and J.T.L. Thong, "A robust focusing and astigmatism correction method for the scanning electron microscope," 1997, scanning 19: 553-563, doi: 10.1002/sca.4950190805.

    \bibitem{Window function wiki}
    "Window function." en.wikipedia.org. \url{https://en.wikipedia.org/wiki/Window_function} (accessed May 13, 2020).
\end{thebibliography}
\end{document}
