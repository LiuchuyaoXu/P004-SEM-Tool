\documentclass[12pt, twocolumn]{report}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{setspace}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{listings}
\usepackage[lighttt]{lmodern}

\onehalfspacing
\geometry{margin=25mm}
\lstset{basicstyle=\ttfamily, keywordstyle=\bfseries}

\author{Liuchuyao Xu}
\title{General-purpose Computing on Graphics Processing Units for Real-time Analysis of Scanning Electron Microscope Images}

\begin{document}
\maketitle

\begin{abstract}
\end{abstract}

\chapter{Introduction}
\paragraph{}
The scanning electron microscope (SEM) is a type of microscope that produces images using signals generated from the interaction between electrons and the surface under observation. It has higher resolutions than traditional optical microscopes---an SEM can have a resolution lower than one nanometre, whereas that of an optical microscope is limited to a few hundred nanometres. This has benefited a variety of fields by allowing scientists to see micro-details of objects that were previously impossible to observe. For example, the SEM can be used to study structures of semiconductor devices \cite{SEM for semiconductors} and to view changes in bacterial cells \cite{SEM for baterial cells}.

\paragraph{}
Fig. \ref{SEM basic construction} illustrates how an SEM works. The electron gun generates an electron beam, which is transformed into an electron probe after passing through the condenser lens and objective lens. It is then scanned across the specimen under the effect of the scanning coil. As a result of the interaction between the incident electrons and the specimen, some electrons (which are called secondary electrons) are emitted from the specimen. The detector collects the secondary electrons and generates signals based on their energy levels. The display unit uses the signals to produce one image after each complete scan of the specimen.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.45\textwidth]{Figures/SEM basic construction.jpg}
    \caption{Basic construction of an SEM \cite{SEM A to Z}.}
    \label{SEM basic construction}
\end{figure}

\paragraph{}
Many image analysis methods have applications in the field of SEM, and the fast Fourier transform is an especially popular one since it can be used to evaluate the focusing and astigmatism of an SEM [see section \ref{Software FFT}]; however, due to the complexity of the algorithm and a lack of fast hardware, real-time analysis had been either impossible or impractical in the past. In 1997, with an advanced central processing unit (CPU)---the Pentium Pro, it was only possible to achieve a refresh rate of 0.6 frames per second for 8-bit 1024 $\times$ 1024 input images \cite{SEM image sharpness measurement}. Although the enhancement of CPUs has enabled faster computations throughout the years, what really brings the speed to a different level is the development of graphics processing units (GPUs).

\paragraph{}
The GPU used to be a highly specialised hardware that was designed to excel in rendering complex, high-resolution, real-time 3D scenes for games; however, its special architecture has made it outperform CPUs in many other areas and resulted in the birth of the idea of general-purpose computing on graphics processing units (GPGPU) \cite{GPU computing}, where GPUs are used to perform computations that are traditionally handled by CPUs.

\paragraph{}
A key characteristic of GPUs is massive parallelism. Depending on their positions, pixels in a 3D scene often require different processing to achieve effects such as lighting, blurring, and fogging. GPUs do this by breaking down the scene into fragments and manipulating each fragment individually. Modern GPUs have thousands of parallel processor cores each running tens of parallel threads to meet the the high requirement for parallelism. For example, the NVIDIA GeForce GTX 1060 has 1280 cores and each of them is capable of running 16 threads; a similarly prices CPU---the Intel i7-7700---has only 4 cores each running 8 threads. It is worth mentioning that the processing cores on a GPU are not as sophisticated as a full CPU and run at a lower clock frequency. The processor clock frequency of the GTX 1060 is 1708 MHz whereas the i7-7700 has a base processor frequency of 3600 MHz. This means that GPGPU is more useful for applications that involve simple, repetitive, parallel tasks. A recent example is deep learning, where computations that follow the same logical sequence of control need to be performed on a deep network of nodes. Typical deep learning networks in 2015 consist of about one million nodes \cite{Deep learning}, which means that the computations cannot be done efficiently on a CPU.

\paragraph{}
This report investigates the gain in calculation speeds from the use of GPUs, and presents a diagnostic tool developed based on GPGPU, which can perform real-time histogram equalisation and FFT on images captured by an SEM. The tool was used to implement an automatic focusing and astigmatism correction algorithm, and the results are discussed.

\chapter{The gain in calculation speeds from the use of GPUs}
\section{GPU computing}
\paragraph{}
The GPU is designed to meet the high demand in parallelism for fast rendering of scenes on displays. For example, a 1080p display refreshing at 60 Hz requires $60 \times 1920 \times 1080 = 124,416,000$ values to be computed in each second, which cannot be done efficient enough in the sequential manner used by the CPU. It describes an image using graphics primitives as shown in Fig. \ref{GPU graphics primitives}. To construct the image, the primitives are passed through the graphics pipeline of the GPU, which can be divided into the following stages:
\begin{itemize}
    \item Vertex generation. A list of vertices are generated to represent the image as a 3D triangle mesh, as illustrated by Fig. \ref{GPU graphics triangle mesh}.
    \item Triangle generation. The vertices are assembled into triangles, which are the fundamental hardware-supported primitive in modern GPUs.
    \item Fragment generation. The triangles are mapped to blocks of pixels on the screen; each block is called a ``fragment''.
    \item Fragment processing. The fragments are shaded based on colour and texture information to determine their final colour.
    \item Composition. A final image is created by assembling the fragments.
\end{itemize}
The processing of primitives within each stage follow the same logical sequence of control, but the data are different. This pattern is called ``single instruction multiple data'' (SIMD). The GPU has a large array of SIMD, multi-threaded processing cores sharing the same global memory, and it divides the cores among the stages such that the pipeline is divided in \textit{space}, not time. Each primitive is processed by a thread of one of the processors.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.45\textwidth]{Figures/GPU graphics primitives.jpg}
    \caption{Graphics primitives \cite{GPU architecture lecture}.}
    \label{GPU graphics primitives}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.45\textwidth]{Figures/GPU graphics triangle mesh.jpg}
    \caption{Representing an image as a 3D triangle mesh \cite{GPU architecture lecture}.}
    \label{GPU graphics triangle mesh}
\end{figure}

The parallel structure of the GPU can also provide a significant speed improvement in general-purpose computing. Take the addition of two vectors of size $N$ as an example:
\begin{equation*}
    \boldsymbol{v_3} = \boldsymbol{v_1} + \boldsymbol{v_2}
\end{equation*}
A single-threaded CPU divides the task in time and does:
\begin{align*}
    & \text{Time 1: } \boldsymbol{v_3}[0] = \boldsymbol{v_1}[0] + \boldsymbol{v_2}[0] \\
    & \vdots \\
    & \text{Time n: } \boldsymbol{v_3}[n] = \boldsymbol{v_1}[n] + \boldsymbol{v_2}[n] \\
\end{align*}
This results in a time complexity of $O(N)$. The GPU can in theory achieve a time complexity of $O(1)$ by dividing the task in space, i.e. among threads, and doing:
\begin{align*}
    & \text{Time 1: }
\begin{cases}
    & \text{Thread 1: } \boldsymbol{v_3}[0] = \boldsymbol{v_1}[0] + \boldsymbol{v_2}[0] \\
    & \vdots \\
    & \text{Thread n: } \boldsymbol{v_3}[n] = \boldsymbol{v_1}[n] + \boldsymbol{v_2}[n] \\
\end{cases}
\end{align*}
The task is an SIMD task---the program takes one element from each of the vectors and perform addition on them, but the data handled by each thread is different, it can therefore make full use of the SIMD cores of the GPU. When $N$ is small, the overhead in allocating the resources means that the speed improvement is negligible; as $N$ grows larger, the reduction in time complexity quickly compensates for the overhead and makes the GPU much faster than the CPU; however, when $N$ is too big, the GPU will run out of resources, which sets a cap to its performance.

\paragraph{}
Prior to 2007, to use GPUs for general-purpose computing, the user must write programs using the graphics application programming interface (API) since it was the only interface to GPU hardware. The programming model can be summarised as below:
\begin{itemize}
    \item The user specifies geometry that covers a region on the screen.
    \item The user sets parameters of the pipeline (e.g., ``lighting'' and ``texture'' information).
    \item The user provides the fragment processing program (kernel).
    \item The GPU produces an output ``image'' and stores it in global memory.
\end{itemize}
This was a major problem in GPGPU because many general-purpose tasks have nothing to do with graphics and are difficult to implement using the graphics API. 

\paragraph{}
The introduction of CUDA changed the situation by providing a more natural, direct, non-graphics interface. The new programming model can be summarised as below:
\begin{itemize}
    \item The user defines the computation as a structured grid of threads.
    \item The GPU executes each thread and stores the results in global memory.
\end{itemize}
This model allows the user to directly define threads that are run on the processing cores of the GPU, eliminating the complexity in translating the program into graphics pipeline language, which makes it easier for the user to take full advantage of the GPU's power. The following section describes an experiment conducted to determine the gain in calculation speeds from using CUDA.

\section{Experiment, results and discussions}
\paragraph{}
An experiment was set up to compare the performance of a middle-range GPU---the NVIDIA GeForce GTX 1060---and a similarly priced CPU---the Intel Core i7-7700, for the following operations:
\begin{itemize}
    \item Addition of two random vectors of size $N$, which has a time complexity of $O(N)$ if done without parallelism, as described in the previous section.
    \item Multiplication of two random matrices of dimension $N \times N$, which has a time complexity of $O(N^3)$ if done without parallelism (and without using special algorithms such as the Coppersmith-Winograd algorithm).
\end{itemize}
Ten test samples were taken for each set of parameters and the average results are shown in Fig. \ref{Test GPU and CPU}. As can be seen, the GPU provides a significant improvement on calculation speeds when there are a few millions of elements to be processed (which is typical in image processing).

This has allowed the development of a real-time diagnostic tool for the SEM with useful framerates, which is discussed in the next chapter.

\begin{figure*}[htbp]
    \centering
    \begin{subfigure}{0.8\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{Figures/Test GPU and CPU vector addition.png}
        \caption{Vector addition.}
        \label{Test GPU and CPU vector addition}
    \end{subfigure}
    \begin{subfigure}{0.8\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{Figures/Test GPU and CPU matrix multiplication.png}
        \caption{Matrix multiplication.}
        \label{Test GPU and CPU matrix multiplication}
    \end{subfigure}
    \caption{Performance test results of the GPU and CPU}
    \label{Test GPU and CPU}
\end{figure*}

\chapter{A real-time diagnostic tool for SEMs}
\section{The Design}
\paragraph{Features}
The aim of the tool is to support interactive real-time diagnosis of SEM images that assists the operator or automated procedures, and it has two main features:
\begin{itemize}
    \item Real-time histogram calculation and histogram equalisation.
    \item Real-time FFT calculation.
\end{itemize}

\paragraph{Design principle}
Considering that the tool may serve as the foundation stone for many further developments, the design of the software has a strong emphasis on readability and maintainability.

\paragraph{Selection of programming language}
The SEM used for the project is made by Carl Zeiss AG, which provides an API for controlling the SEM and grabbing images from it. The API supports C++ and thus makes it a possible programming language for the project. Being a relatively low-level compiled language makes C++ extremely fast and useful for speed-critical applications. However, it also means that C++ has a complex syntax, which could significantly slow down development if the user does not have enough experience with it. Considering the time scale of the project and to make development easier for people who will continue the work, Python is selected instead of C++ as the programming language. It has a much simpler syntax and is widely supported; with careful design, it has proved to produce useful results despite its slower speed (see later sections).

\paragraph{Modules of the software}
The software is highly modularised for maximising readability and maintainability. This also makes it easier to translate the program into C++ later if faster speed is needed since C++ is mostly used in an object-oriented manner. The software is divided into six main classes as shown in Fig. \ref{Software class diagram}:
\begin{itemize}
    \item \textit{SEM\_API} is a Python wrapper for the native SEM API, which allows the user to directly control the SEM in Python.
    \item \textit{SemImage} encapsulates variables and methods that are directly relevant to an SEM image.
    \item \textit{SemImageGrabber} is a helper class that helps obtain image data from the SEM and create instances of \textit{SemImage} from them. Images can be obtained in two ways:
    \begin{itemize}
        \item From the SEM.
        \item From a local folder, which is helpful when the SEM is not available.
    \end{itemize}
    \textit{SemImageGrabber} detects if the SEM is available and decides on which way to use.
    \item \textit{SemTool} handles the creation and rendering of the graphical user interface (GUI). Fig. \ref{Software GUI} shows a screenshot of the control panel. The pushbuttons open a window for the corresponding plot and the radio buttons select algorithms to be performed on the image [see section TBC]. The plots are shown on different windows and can be opened and closed individually. This improves framerate by allowing the user to close unneeded windows, and also makes it easier to add other plots later. Table \ref{Test software framerates} shows that the improvement is significant, as rendering windows is a major time-consuming process of the software. When only one window is opened, a refresh rate of about 16 frames per second is possible. There are two ways for updating the plots, and the first one is to re-render the whole window. This wastes time since some components are always the same and do not need to be re-rendered, such as the window title and the axes. Therefore, \textit{SemTool} uses the second method, where only the data to be plotted are updated. This directly modifies the relevant data in the memory of the GPU, thereby avoiding re-rendering the whole window. Tests have shown that if the first method is used, the time taken to update each frame when there is only one plot opened will be 90 ms instead of 60 ms.
    \item \textit{SemCorrector} implements the automatic focusing and astigmatism correction algorithm and uses a helper class \textit{Masker} to achieve fast computation [see section TBC]. Due to the impact of the COVID-19 pandemic, the algorithm has not been fully tested and is therefore not integrated to the GUI yet.
\end{itemize}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.45\textwidth]{Figures/Software class diagram.png}
    \caption{Class diagram of the software in unified modelling language (UML).}
    \label{Software class diagram}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.45\textwidth]{Figures/Software screenshot.jpg}
    \caption{Screenshot of the GUI.}
    \label{Software GUI}
\end{figure}

\begin{table}[htbp]
    \caption{Results of software framerate test}
    \begin{center}
    \begin{tabular}{|c|c|}
    \hline
    \textbf{Number of} & \textbf{Time taken to} \\
    \textbf{plots opened} & \textbf{update each frame} \\
    \hline
    zero & 15 ms \\
    \hline
    one & 60 ms \\
    \hline
    three & 160 ms \\
    \hline
    \multicolumn{2}{l}{$^{\mathrm{a}}$The numbers are approximate.} \\
    \multicolumn{2}{l}{$^{\mathrm{b}}$8-bit grey-scale 1024 $\times$ 768 input images.} \\
    \multicolumn{2}{l}{$^{\mathrm{c}}$On Intel Core i7 and NVIDIA GTX 1060 }
    \end{tabular}
    \label{Test software framerates}
    \end{center}
\end{table}

\section{Real-time histogram calculation and histogram equalisation}
\paragraph{}
Histograms use bars to represent the shades of tones (level) that make up an image. The grey level (brightness level) histogram is the most relevant histogram to SEM images, since SEMs translate the energy of the secondary electrons directly into a grey level. The height of the bars in a grey level histogram can be calculated by
\begin{equation}
    n_l = \frac{1}{P} \sum_{p} I(l_p=l),
\end{equation}
where $n_l$ is the normalised number of pixels of grey level $l$, $P$ is the total number of pixels in the image and $l_p$ is the grey level of the $p_{th}$ pixel. 

\paragraph{}
Fig. \ref{Histogram equalisation inital image} shows an 8-bit grey-scale image, i.e. its depth of digitisation is 8-bit and it has 256 grey levels. Fig. \ref{Histogram equalisation inital image histogram} shows the histogram of the image and its integral. As can be seen in the histogram, most pixels are concentrated in the middle of the greyscale. This is reflected by the fact that the image is missing its highlights and shadows.

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.4\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{Figures/Histogram equalisation inital image.jpg}
        \caption{Original image.}
        \label{Histogram equalisation inital image}
    \end{subfigure}
    \begin{subfigure}{0.4\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{Figures/Histogram equalisation inital image histogram.png}
        \caption{Histogram of the original image.}
        \label{Histogram equalisation inital image histogram}
    \end{subfigure}
    \begin{subfigure}{0.4\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{Figures/Histogram equalisation final image.jpg}
        \caption{Histogram-equalised image.}
        \label{Histogram equalisation final image}
    \end{subfigure}
    \begin{subfigure}{0.4\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{Figures/Histogram equalisation final image histogram.png}
        \caption{Histogram of the histogram-equalised image.}
        \label{Histogram equalisation final image histogram}
    \end{subfigure}
    \caption{Histogram and histogram equalisation.}
    \label{Histogram and histogram equalisation}
\end{figure}

\paragraph{}
Histogram equalisation is a method for adjusting the distribution of pixel intensities of an image, to improve its overall contrast. Effectively, it is achieved by spreading out more frequent intensity values. To perform histogram equalisation, firstly obtain the integral of the histogram using
\[s_l = \sum_{i=1}^{l} n_i,\]
where $s_l$ is the value of the integral at grey level $l$. The integral spans from 0 to 1 as the histogram is normalised. Scale the integral by the maximum grey level and perform rounding to create the transform function
\begin{equation}
    f_l = \lfloor s_lL \rfloor,
    \label{Histogram equalisation transform function}
\end{equation}
If a pixel in the original image has a grey level $l$, it will have a grey level $f_l$ in the transformed image. For example, if all pixels in the original image are concentrated between grey level 100 to 200, the pixels of level 100 will become 0 in the new image while the pixels of level 200 will become 255 (assuming an 8-bit image).

\paragraph{}
The result is more noticeable when the image has low contrast, such as the one shown in Fig. \ref{Histogram equalisation inital image}. The histogram-equalised version of it is given in Fig. \ref{Histogram equalisation final image} and the new histogram in Fig. \ref{Histogram equalisation final image histogram}. More details are now visible as the contrast has been enhanced.

\paragraph{}
The most time-consuming part of histogram equalisation is to map all pixels in the original image to their new values using the transform function \eqref{Histogram equalisation transform function}. This can be implemented using CPU code in one line:
\begin{lstlisting}
newImage = 
  map(lambda x: f[x], image)
\end{lstlisting}
\lstinline{f} is an array that serves as the transformation function, if the original pixel value is x, the new value should be \lstinline{f[x]}. The \lstinline{lambda} operator is a way to create small anonymous functions, which are throw-away and are only needed where they are created. It improves conciseness and readability by reducing code bloat. \lstinline{lambda x: f[x]} creates an anonymous function that returns \lstinline{f[x]} when given \lstinline{x}, and \lstinline{map()} uses this function to transform all pixels in \lstinline{image}. This gives a time complexity of $O(N^2)$ which is not optimal. A smaller time complexity can be achieved using the GPU code:
\begin{lstlisting}
map = cupy.ElementwiseKernel(
  'T x, raw T f', 'T xNew',
  'xNew = f[x]',
  'map'
)
newImage = map(image, f)
\end{lstlisting}
\lstinline{cupy.ElementwiseKernel()} defines a kernel that the GPU uses to process the input data in parallel. Tests have shown that the use of GPU can increase the speed by 2 times, as summarised in Table \ref{Software speed comparison}. In theory, the factor of speed improvement should be similar as that for calculating the histogram, since it also requires iterating through all pixels in the image. However, the code implementations introduce overheads which limit the improvement in speed.

\begin{table}[htbp]
    \caption{Speed comparison between CPU and GPU}
    \begin{center}
    \begin{tabular}{|c|c|c|}
    \hline
    \textbf{Algorithm} & \textbf{CPU} & \textbf{GPU} \\
    \hline
    Apply Hanning window & 16 ms & 9 ms \\
    \hline
    Calculating histogram & 30 ms & 2 ms \\
    \hline
    Histogram equalisation & 9 ms & 5 ms \\
    \hline
    Fast Fourier transform & 60 ms & 8 ms \\
    \hline
    \multicolumn{3}{l}{$^{\mathrm{a}}$The results are averaged over 10 samples.} \\
    \multicolumn{3}{l}{$^{\mathrm{b}}$8-bit greyscale 1024 $\times$ 768 input images.} \\
    \multicolumn{3}{l}{$^{\mathrm{c}}$On Intel Core i7 and NVIDIA GTX 1060.}
    \end{tabular}
    \label{Software speed comparison}
    \end{center}
\end{table}

\section{Real-time fast Fourier transform calculation}

\chapter{Automatic focusing and astigmatism correction algorithm}

\chapter{Conclusions}

\begin{thebibliography}{00}
    \bibitem{SEM for semiconductors}
    C. REEVES, ``The uses of scanning electron microscopy for studying semiconductor devices,'' International Journal of Electronics, vol. 77, no. 6, pp. 919-928, 1994, doi: 10.1080/00207219408926111.

    \bibitem{SEM for baterial cells}
    T. Cushnie, N. O’Driscoll and A. Lamb, ``Morphological and ultrastructural changes in bacterial cells as an indicator of antibacterial mechanism of action,'' Cellular and Molecular Life Sciences, vol. 73, no. 23, pp. 4471-4492, 2016, doi: 10.1007/s00018-016-2302-2.

    \bibitem{SEM A to Z}
    ``SEM A to Z,'' Jeol.co.jp, [Online], available: \url{https://www.jeol.co.jp/en/applications/pdf/sm/sem_atoz_all.pdf}. [Accessed: 18 May 2020].

    \bibitem{SEM image sharpness measurement}
    A. Vladár, M. Postek and M. Davidson, ``Image sharpness measurement in scanning electron microscopy-part II,'' Scanning, vol. 20, no. 1, pp. 24-34, 2006, doi: 10.1002/sca.1998.4950200104.

    \bibitem{GPU computing}
    J. D. Owens, M. Houston, D. Luebke, S. Green, J. E. Stone and J. C. Phillips, ``GPU Computing,'' in Proceedings of the IEEE, vol. 96, no. 5, pp. 879-899, May 2008, doi: 10.1109/JPROC.2008.917757.

    \bibitem{Deep learning}
    Ian Goodfellow; Yoshua Bengio; Aaron Courville, ``Deep learning,'' in Deep Learning, The MIT Press, 2017, p. 23.

    \bibitem{GPU architecture lecture}
    ``GPU Architecture and CUDA Programming,'' Carnegie Mellon University, 2017, [Online], available: \url{http://15418.courses.cs.cmu.edu/spring2017/home}. [Accessed: 19 May 2020].
\end{thebibliography}
\end{document}
